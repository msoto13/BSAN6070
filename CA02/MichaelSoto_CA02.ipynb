{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCZYXwtCsL_y"
      },
      "source": [
        "CA02: This is a eMail Spam Classifers that uses Naive Bayes supervised machine learning algorithm. \n",
        "\n",
        "In this assignment you will ...\n",
        "1. Complete the code such a way that it works correctly with this given parts of the program.\n",
        "2. Explain as clearly as possible what each part of the code is doing. Use \"Markdown\" texts and code commenting to explain the code\n",
        "\n",
        "IMPORTANT NOTE:\n",
        "\n",
        "The path of your data folders 'train-mails' and 'test-mails' must be './train-mails' and './test-mails'. This means you must have your .ipynb file and these folders in the SAME FOLDER in your laptop or Google Drive. The reason for doing this is, this way the peer reviewes and I would be able to run your code from our computers using this exact same relative path, irrespective of our folder hierarchy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "4p_DvtT7sOIr",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# Import all other necessary libraries. Your code below ...\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make Dictionary function to give the most common 3000 words"
      ],
      "metadata": {
        "id": "cnP7nv1N4IoQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "jjKF0nIMwz8_",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "'''This function builds a Dictionary of most common 3000 words from all the email content. \n",
        "First it adds all words and symbols in the dictionary. \n",
        "Then it removes all non-alpha-numeric characters and any single character alpha-numeric characters. \n",
        "After this is complete it shrinks the Dictionary by keeping only most common 3000 words in the dictionary. '''\n",
        "\n",
        "def make_Dictionary(root_dir):\n",
        "  all_words = []\n",
        "  emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)]\n",
        "  for mail in emails:\n",
        "    with open(mail) as m:\n",
        "      for line in m:\n",
        "        words = line.split()\n",
        "        all_words += words\n",
        "  dictionary = Counter(all_words)\n",
        "  list_to_remove = list(dictionary)\n",
        "\n",
        "  for item in list_to_remove:\n",
        "    if item.isalpha() == False:\n",
        "      del dictionary[item]\n",
        "    elif len(item) == 1:\n",
        "      del dictionary[item]\n",
        "  dictionary = dictionary.most_common(3000)\n",
        "  return dictionary\n",
        "            "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating feature columns and labels"
      ],
      "metadata": {
        "id": "ZsMEcD2Q4VIR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "dmVW5xNlyOFc",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "\"\"\"This function extracts feature columns and populates their values \n",
        "(Feature Matrix of 3000 comumns and rows equal to the number of email files). \n",
        "The function also analyzes the File Names of each email file and decides if it's \n",
        "a Spam or not based on the naming convention. The function also \n",
        "creates the Labelled Data Column. This function is used to extract the training dataset \n",
        "as well as the testing dataset and returns the Feature Dataset and the Label column.\"\"\"\n",
        "\n",
        "def extract_features(mail_dir):\n",
        "  files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)]\n",
        "  features_matrix = np.zeros((len(files),3000))\n",
        "  train_labels = np.zeros(len(files))\n",
        "  count = 1;\n",
        "  docID = 0;\n",
        "  for fil in files:\n",
        "    with open(fil) as fi:\n",
        "      for i, line in enumerate(fi):\n",
        "        if i ==2:\n",
        "          words = line.split()\n",
        "          for word in words:\n",
        "            wordID = 0\n",
        "            for i, d in enumerate(dictionary):\n",
        "              if d[0] == word:\n",
        "                wordID = i\n",
        "                features_matrix[docID,wordID] = words.count(word)\n",
        "      train_labels[docID] = 0;\n",
        "      filepathTokens = fil.split('/')\n",
        "      lastToken = filepathTokens[len(filepathTokens)-1]\n",
        "      if lastToken.startswith(\"spmsg\"):\n",
        "        train_labels[docID] = 1;\n",
        "        count = count + 1\n",
        "      docID = docID + 1\n",
        "  return features_matrix, train_labels                "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "zoq-rE7Mx0pp",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Enter the \"path\" of your \"train_mails\" and \"test-mails\" FOLDERS in this cell ...\n",
        "TRAIN_DIR = '/content/drive/My Drive/Data/train-mails'\n",
        "TEST_DIR = '/content/drive/My Drive/Data/test-mails'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HZR4xlVy76w",
        "outputId": "9d3dfdac-8b6f-45b4-f801-eea6dca6b0a1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This step is creating a training dictionary"
      ],
      "metadata": {
        "id": "DDOacY_H4g-E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "134lmhauyQxE",
        "outputId": "e6006e12-5020-40d7-ebf7-636925832efe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading and processing emails from TRAIN and TEST folders\n"
          ]
        }
      ],
      "source": [
        "dictionary = make_Dictionary(TRAIN_DIR)\n",
        "\n",
        "print (\"reading and processing emails from TRAIN and TEST folders\")\n",
        "features_matrix, labels = extract_features(TRAIN_DIR)\n",
        "test_features_matrix, test_labels = extract_features(TEST_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"The section is the main Program that calls the two functions above. \n",
        "First it \"trains\" the model using model.fit function and Training Dataset. \n",
        "After that it scores the Test Data set by running the Trained Model with the Test Data set. \n",
        "At the end it prints the model performance in terms of accuracy score.\"\"\"\n",
        "\n",
        "model = GaussianNB()\n",
        "\n",
        "print (\"Training Model using Gaussian Naibe Bayes algorithm .....\")\n",
        "model.fit(features_matrix, labels)\n",
        "print (\"Training completed\")\n",
        "print (\"testing trained model to predict Test Data labels\")\n",
        "predicted_labels = model.predict(test_features_matrix)\n",
        "print (\"Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\")\n",
        "print (accuracy_score(test_labels, predicted_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMtT38lK1QRW",
        "outputId": "9da990d4-1e71-4ce1-b110-bc784236dfbf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Model using Gaussian Naibe Bayes algorithm .....\n",
            "Training completed\n",
            "testing trained model to predict Test Data labels\n",
            "Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\n",
            "0.9653846153846154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results of the code show the features being extracted using the model, the model being trained by the functions, the classification of the data, and finally the accuracy, which is extremely high, at 96.5%"
      ],
      "metadata": {
        "id": "FfKM7k2Z4tyG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5_mPrvN586A"
      },
      "source": [
        "======================= END OF PROGRAM ========================="
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}